{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efe8bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38345477",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import hashlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82daadac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### import, append and export PLASC exclusion data ####\n",
    "\n",
    "folder_path = r'C:\\\\Users\\\\sgranville\\\\Desktop\\\\Uni Work\\\\Dissertation Research\\\\Data\\\\PLASC Exclusions\\\\Raw Data'\n",
    "\n",
    "csv_files = [file for file in os.listdir(folder_path) if file.endswith('.csv')]\n",
    "\n",
    "dfs = []\n",
    "\n",
    "for file in csv_files:\n",
    "    file_path = os.path.join(folder_path, file)\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        df = df.drop(columns=['LEA', 'Estab', 'Surname', 'Forename', 'MiddleNames', 'Gender', 'DOB', 'Sex'], errors='ignore')\n",
    "        df = df.rename(columns={'StartDate': 'Exclusion_StartDate', \n",
    "                                'Reason': 'Exclusion_Reason', \n",
    "                                'ExclusionCategory': 'Exclusion_Category', \n",
    "                                'SessionsMissed': 'Exclusion_SessionsMissed'})\n",
    "        dfs.append(df)\n",
    "    except pd.errors.ParserError as e:\n",
    "        print(f\"Error reading file {file}: {e}\")\n",
    "\n",
    "merged_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "merged_df.to_csv(r'C:\\\\Users\\\\sgranville\\\\Desktop\\\\Uni Work\\\\Dissertation Research\\\\Data\\\\PLASC Exclusions\\\\exclusions_merged.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335791a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### import, append and export PLASC pupil data ####\n",
    "\n",
    "folder_path = r'C:\\\\Users\\\\sgranville\\\\Desktop\\\\Uni Work\\\\Dissertation Research\\\\Data\\\\PLASC Pupil\\\\Raw Data'\n",
    "\n",
    "# Initialize an empty DataFrame to store the merged data\n",
    "merged_df = pd.DataFrame()\n",
    "\n",
    "# List to store already merged headers\n",
    "merged_headers = []\n",
    "\n",
    "# Columns that need to match for appending\n",
    "matching_columns = ['Year', 'Estab', 'UPN', 'Gender', 'DOB', 'NCYearActual', \n",
    "                     'Ethnicity', 'SENprovision', 'FSMeligible', \n",
    "                     'PostCode', 'EALAcquisition']\n",
    "\n",
    "# Columns to import from each CSV\n",
    "columns_to_import = ['Year', 'Estab', 'UPN', 'Gender', 'DOB', 'NCYearActual', \n",
    "                     'Ethnicity', 'SENprovision', 'FSMeligible', \n",
    "                     'PostCode', 'EALAcquisition']\n",
    "\n",
    "# Iterate over each CSV file in the folder\n",
    "for file_name in os.listdir(folder_path):\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "    if file_name.endswith('.csv'):\n",
    "        # Read the CSV file\n",
    "        df = pd.read_csv(file_path, dtype={'Year': str, 'Estab': str, 'UPN': str, 'Gender': str})\n",
    "\n",
    "        # Check if 'Sex' column exists and rename it to 'Gender'\n",
    "        if 'Sex' in df.columns:\n",
    "            df.rename(columns={'Sex': 'Gender'}, inplace=True)\n",
    "\n",
    "        # Ensure 'Gender' column is included\n",
    "        if 'Gender' not in df.columns:\n",
    "            df['Gender'] = pd.NA\n",
    "\n",
    "        # Convert columns used for merging to string data type\n",
    "        for col in matching_columns:\n",
    "            if col in df.columns:\n",
    "                df[col] = df[col].astype(str)\n",
    "\n",
    "        # Check if data in specified columns match before appending\n",
    "        if merged_df.empty or merged_df.astype(str).merge(df[columns_to_import], on=matching_columns, how='inner').empty:\n",
    "            # Append the data to the merged DataFrame\n",
    "            merged_df = pd.concat([merged_df, df[columns_to_import]], ignore_index=True)\n",
    "\n",
    "# Save the merged DataFrame to a new CSV file\n",
    "merged_df.to_csv(r'C:\\\\Users\\\\sgranville\\\\Desktop\\\\Uni Work\\\\Dissertation Research\\\\Data\\\\PLASC Pupil\\\\pupil_merged.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe43792",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183e164e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### combine PLASC pupil and exclusion csv files ####\n",
    "\n",
    "# Read the CSV files\n",
    "pupil_df = pd.read_csv('C:\\\\Users\\\\sgranville\\\\Desktop\\\\Uni Work\\\\Dissertation Research\\\\Data\\\\PLASC Pupil\\\\pupil_merged.csv')\n",
    "exclusions_df = pd.read_csv('C:\\\\Users\\\\sgranville\\\\Desktop\\\\Uni Work\\\\Dissertation Research\\\\Data\\\\PLASC Exclusions\\\\exclusions_merged.csv')\n",
    "\n",
    "# Merge the two DataFrames on the columns 'UPN' and 'Year'\n",
    "merged_df = pd.merge(pupil_df, exclusions_df, on=['UPN', 'Year'], how='left')\n",
    "\n",
    "# Save the merged DataFrame to a new CSV file\n",
    "merged_df.to_csv('C:\\\\Users\\\\sgranville\\\\Desktop\\\\Uni Work\\\\Dissertation Research\\\\Data\\\\merged_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e80bcf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append historic attendance data with data for the current appacemic year\n",
    "\n",
    "hist_att_df = pd.read_csv('C:\\\\Users\\\\sgranville\\\\Desktop\\\\Uni Work\\\\Dissertation Research\\\\Data\\\\Attendance\\\\Attendance_2013to2023.csv')\n",
    "curr_att_df = pd.read_csv('C:\\\\Users\\\\sgranville\\\\Desktop\\\\Uni Work\\\\Dissertation Research\\\\Data\\\\Attendance\\\\Attendance_2023to2024.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f617f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_att_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073f10ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_att_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e7b1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [hist_att_df, curr_att_df]\n",
    "att_df = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f221069",
   "metadata": {},
   "outputs": [],
   "source": [
    "att_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fec415",
   "metadata": {},
   "outputs": [],
   "source": [
    "att_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52f7560",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8114832b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename 'Estab' column in merged_df\n",
    "merged_df = merged_df.rename(columns={\"Estab\": \"DES_NO\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a491401",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['Year'] = merged_df['Year'].astype(str).str[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d672ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "att_df['ACYEAR'] = att_df['ACYEAR'].astype(str).str[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98528725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename 'UP_ID' and 'ACYEAR' columns in att_df\n",
    "att_df = att_df.rename(columns={\"UP_ID\": \"UPN\", \"ACYEAR\": \"Year\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9959ca14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert datatype of 'Year' column from string to integer \n",
    "att_df['Year'] = att_df['Year'].astype(int)\n",
    "merged_df['Year'] = merged_df['Year'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d8573a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# incremet the Year by 1 in the attendance dataframe\n",
    "att_df['Year'] = att_df['Year'] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd19dd72",
   "metadata": {},
   "outputs": [],
   "source": [
    "att_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec7a7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e065cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "distinct_years = att_df['Year'].unique()\n",
    "distinct_years.sort()\n",
    "print(distinct_years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917da39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "distinct_years = merged_df['Year'].unique()\n",
    "distinct_years.sort()\n",
    "print(distinct_years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97d3d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### combine Attendance with merged_data.csv ####\n",
    "\n",
    "# Merge the two DataFrames on the columns 'DES_NO', 'UPN' and 'Year'\n",
    "att_merged_df = pd.merge(merged_df, att_df, on=['Year', 'DES_NO', 'UPN'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a7b3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "att_merged_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830a109c",
   "metadata": {},
   "outputs": [],
   "source": [
    "att_merged_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec816281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the merged DataFrame to a new CSV file\n",
    "att_merged_df.to_csv('C:\\\\Users\\\\sgranville\\\\Desktop\\\\Uni Work\\\\Dissertation Research\\\\Data\\\\att_merged_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f810782d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### WIMD Postcodes rectified and spaces removed in both files outside of Python #####\n",
    "#### Do THIS IN PYTHON!! ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc52bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### combine WIMD with merged_data.csv #### Welsh Postcode\n",
    "\n",
    "# Read the merged data CSV file\n",
    "merged_df = pd.read_csv('C:\\\\Users\\\\sgranville\\\\Desktop\\\\Uni Work\\\\Dissertation Research\\\\Data\\\\att_merged_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e447359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hash the UPN\n",
    "\n",
    "# Convert column to string\n",
    "#merged_df['CLIENTNUM'] = df['CLIENTNUM'].astype(str)\n",
    "\n",
    "# Apply hashing function to the column\n",
    "merged_df['UPN'] = merged_df['UPN'].apply(\n",
    "\n",
    "    lambda x: \n",
    "        hashlib.sha256(x.encode()).hexdigest()z|\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20e3439",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.rename(columns={\"UPN\": \"Hashed_UPN\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011fa0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71275201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove spaces from postcodes\n",
    "\n",
    "att_merged_df['PostCode'] = att_merged_df['PostCode'].str.replace(' ', '')\n",
    "merged_df['PostCode'] = merged_df['PostCode'].str.replace(' ', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25563a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the 'Postcode to WIMD Rank 2019.csv' file\n",
    "postcode_df = pd.read_csv('C:\\\\Users\\\\sgranville\\\\Desktop\\\\Uni Work\\\\Dissertation Research\\\\Data\\\\WIMD\\\\Postcode to WIMD Rank 2019.csv')\n",
    "\n",
    "# Merge the two DataFrames on the 'Postcode' column\n",
    "final_merged_df = pd.merge(merged_df, postcode_df, on='PostCode', how='left')\n",
    "\n",
    "# Save the final merged DataFrame to a new CSV file\n",
    "final_merged_df.to_csv('C:\\\\Users\\\\sgranville\\\\Desktop\\\\Uni Work\\\\Dissertation Research\\\\Data\\\\final_merged_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198aec7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_merged_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be19736c",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_merged_df.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
